---
title: "Modelling the innovation and extinction of archaeological ideas"
author:
  - Ben Marwick, University of Washington
  - Erik Gjesfjeld, University of Cambridge 
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
    fig_caption: yes
    reference_docx: templates/template.docx
bibliography: references.bib
csl: journal-of-archaeological-science.csl
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---


<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

```{r, setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/"
)

library(modelextinctionideas)
```

# Introduction

The history of archaeology is often told as a sequence of prominent individuals and their publications. Due to the focus on big names and big papers, the diversity of archaeological publications is often underestimated. Here we introduce a quantitative method that illuminates historical trends in archaeological writing by investigating a large number of journal articles. We use a Bayesian framework developed for estimating speciation, extinction, and preservation rates from incomplete fossil data. We model archaeological ideas within this framework by equating citations of archaeological literature to occurrences in the fossil record. We obtained reference lists for 12,000 journal articles published between 1975 and 2017 and explored the chronological distribution of cited papers to identify periods of innovation and extinction. We discuss how our modeling approach helps to quantify the diversification of archaeological publications and our broader understanding about the history of archaeological thought.

# Background

```{r load-data}

# #read in the data, resulting from the searchof Web of Science for TOPIC = "Archaeology", document type = "Article", all years

# reload --------------------------------------------------------------------
# this is the fast way to resume:
items_df <- readRDS(paste0(here::here(),"/analysis/data/derived_data/saa2018-data-df.rds"))

library(tidyverse)
items_df <-
items_df %>%
  # remove branding
  filter(authors != "FN Clarivate Analytics Web of Science\nVR 1.0") %>%
  # uniques only
  group_by(authors, title, journal) %>%
  filter(row_number() == 1)

items_wth_refs <-
  items_df %>%
  filter(!is.na(refs)) %>%
  filter(!is.na(year))

# df of refs with year that each ref appears, and ID of citing article
library(stringr)
library(purrrlyr)

# get data frame with refs for each article
# each row is a single citation,
# with info of article that has that citation
# the cited article is in the .out column
# xx <-
# items_wth_refs %>%
#   by_row(..f = function(this_row){
#    unlist(str_split(this_row$refs, "\n"))
#   }) %>%
#   unnest(.out) %>%
#   # remove non-refs
#   filter(!grepl("^[A-Z0-9]{2} .*|^ER$", .out)) %>%
#   filter( .out != "") %>%
#   mutate(.out = trimws(toupper(.out))) %>%
#   mutate(.out = str_replace_all(.out, "[[:punct:]]", ""))
# 
# # extract year of cited work
# xx1 <- 
# xx %>% 
#   mutate(cited_year = as.numeric(str_extract(.out, "[0-9]{4}"))) %>% 
#   mutate(cited_year = ifelse(cited_year %in% 1900:2017, 
#                              cited_year,
#                              NA))

# make sure that a cited item has a year that is earlier than the year of the
# item that cited it. Because sometimes there are in press items with the following
# year, we +1 
# xx2 <- 
#   xx1 %>% 
#   filter(cited_year <= year + 1)

# # # # save this as rds to save time
#  saveRDS(xx2,
#            paste0(here::here(), "/analysis/data/derived_data/items_wth_refs.rds"))


# If we are resuming the analysis we can just start from here, and read in the data
# frame of citations.
xx <- readRDS( paste0(here::here(), "/analysis/data/derived_data/items_wth_refs.rds"))
```

## Basic exploration of the data

```{r}

# how many items do we have?
hm_items <- nrow(items_wth_refs) # 12133

# span what time period?
time_range <- range(items_wth_refs$year) # 1905 2017

# how many 1975-2017
hm_items_1975 <- items_wth_refs %>% filter(year >= 1975) %>% nrow

```

We have `r prettyNum(hm_items, big.mark = ",")` articles in our study. The publication dates range from `r time_range[1]` to  `r time_range[2]`. The bibliographic data for these articles was obtained from a search of Clarivate Analytics Web of Science, using the keyword 'archaeolog' and filtering the results to keep only research articles. 

The distribution of articles is strongly skewed to more recent years, with a rapid increase after the mid-2000s. For the rest of our analysis we're going to limit the time frame to the `r prettyNum(hm_items_1975, big.mark = ",")` published during 1975-2017 because the data from before 1975 is incomplete for some key journals, such as _American Antiquity_.

```{r}
items_wth_refs %>% 
  group_by(year) %>% 
  tally() %>% 
ggplot(aes(year,
           n)) +
  geom_col() +
  theme_bw() +
  ggtitle("Archaeology articles per year") +
  labs(caption = "Data from Clarivate Analytics Web of Science")

items_wth_refs %>% 
  filter(year >= 1975) %>% 
  group_by(year) %>% 
  tally() %>% 
ggplot(aes(year,
           n)) +
  geom_col() +
  theme_bw() +
  ggtitle("Archaeology articles per year (after 1975)") +
  labs(caption = "Data from Clarivate Analytics Web of Science")
```


Let's look at the citations in each of these articles. As expected, the number of citations per year closely follows the distribution of articles per year.

```{r}
# how many citations per year? For only after 1975
xxx <-
xx %>%
  filter(year >= 1975) %>% 
  group_by(year) %>%
  tally()

# # plot, why do we have some gaps? in the 1970s? This is a gap in the Clarivate database
# ggplot(xxx,
#        aes(year,
#             n)) +
#   geom_col() +
#   #scale_y_log10() +
#   theme_bw() +
#   ggtitle("Citations per year in archaeology articles")

library(scales)
ggplot(xxx,
       aes(year,
            n)) +
  geom_col() +
  #scale_y_log10(breaks = trans_breaks('log10', function(x) 10^x),
  #                labels = trans_format('log10', math_format(10^.x))) +
  theme_bw() +
  ggtitle("Citations per year in archaeology articles (since 1975)")
```


With such a large data set we can answer a few basic interesting questions, for example:

- What is the most cited paper?    
- What is the most cited paper per decade?

Here are the top ten most cited items overall:

```{r}
most_cited <- 
  xx %>% 
  filter(year >= 1975) %>% 
  count(.out, sort = TRUE)  %>% 
  slice(1:10)

knitr::kable(most_cited)
```

And here are the most cited items per decade (there is a tie for the 1970-1980 data):

```{r}
# from https://gist.github.com/benmarwick/5826552
## create new column that is 'decade'
# first make a lookup table to get a decade for each individual year
year1 <- 1900:2050
my_seq <- seq(year1[1], year1[length(year1)], by = 10)
indx <- findInterval(year1, my_seq)
ind <- seq(1, length(my_seq), by = 1)
labl1 <- paste(my_seq[ind], my_seq[ind + 1], sep = "-")[-42]
dat1 <- data_frame(year = year1, 
                   decade = labl1[indx])
# merge the decade column onto my_df
my_df <- left_join(xx, dat1, by = 'year')

most_cited_per_decade <- 
   my_df %>% 
  filter(year >= 1975) %>% 
  group_by(decade) %>% 
  count(.out, sort = TRUE) %>% 
  filter(n == max(n))

knitr::kable(most_cited_per_decade)
```

We can zoom in on one article, Binford's "Archaeology as Anthropology", published in 1962. The plot shows the proportion of all citations in each year that are Binford 1962. 

At a glance, we have three phases, roughly, high-frequency citations during 1962-1980, medium frequency during 1980-1990, and low-frequency 1990-present. This pattern suggest that this paper might eventually go 'extinct' in the literature and not longer be cited. 

We can model rates of extinction using tools from palaeontology. 

```{r}
# age distribution of "Archaeology as Anthropology" citations, as a proportion
# of all citations in each year
binford_1962_cites_per_year <-
  xx %>%
  filter(year >= 1975) %>% 
  filter(grepl("BINFORD LR 1962 AM ANTIQUITY V28 P217", 
               .out)) %>%
    group_by(year) %>%
    summarise(count = n()) %>%
    left_join(xxx, 
              by = "year") %>%
    mutate(prop = count / n) %>%
    distinct(year, 
             prop, 
             n)

# plot, why no citations throughout the 1970s?
binford_1962_cites_per_year %>%
  ggplot(aes(year, prop)) +
  geom_col() +
  theme_bw() +
  ylab("Proportion of all\ncitations per year") +
  ggtitle("Citations per year of Binford 1962 (since 1975)")
```

# Innovation and extinction rate modelling

## Preparing the data

### Setting the time unit

These citation data are structured so that we have multiple dates of occurance for each paper. We call this an 'occurrence data' set (as we have dates for each individual occurrence), which can be contrasted with a 'lineage' data set where we'd have only the dates of the first and last instance of each article. 

To compute extinction and innovation rates on these data we must change the time scale so that 0 is the most recent time unit and the higher the number the further back in time.

```{r}
max_year <- max(xx$year)

xx0 <- 
  xx %>% 
  filter(year >= 1975) %>% 
  mutate(time_unit = year)

```

### Formatting Ocurrence Data for PyRate

From https://www.nature.com/articles/palcomms201619 : 

Data sets in occurrence format, such as we have here, provide the opportunity to incoporate uncertainty about the preservation of the observations when analyzing origination and extinction rates. If a researcher does not have a high level of certainty that the dates of first and last occurrence are correct, such as is often the case with fossils or artifacts,  preservation can be informative.

We need a data frame with four columns:

Species: which refers the smallest taxonomic unit, here this is each cited reference. In an archaeological context this would be something like a pottery sherd.

Status: which identifies whether the reference is still used today, we will consider all to be 'extinct'. This would also be true of archaeological artefacts. 

min_age: this refers to the most recent year that a citation appeared, in years before 2017

max_age: this refers to the earliest year that a citation appeared, in years before 2017

trait: this refers to some discrete trait that is known about each entry. In this example, it is the citing article. In an archaeological example, each trait could represent an archaeological site in which the sherd was found at. 

```{r, eval=TRUE}

# must be in this order: c("Species", "Status", "min_age", "max_age", "trait")

refs_occurance_format <- 
xx0 %>% 
  mutate(citing_paper = paste0(authors, 
                               " ",
                               year,
                               " ",
                               title,
                               " ",
                               journal)) %>% 
  select(citing_paper,
         .out, 
         time_unit) 


refs_occurance_format1 <- 
  refs_occurance_format %>% 
  group_by(.out) %>%
  mutate(min_age = min(time_unit), 
         max_age = max(time_unit),
         Status = "extinct") %>% 
  distinct(.out, 
           min_age, 
           max_age, 
           Status)

# drop items that are only cited in a single year
refs_occurance_format2 <- 
refs_occurance_format1 %>% 
  rename(Species = .out
         ) %>% 
    select(Species,
           Status,
           min_age,
           max_age) %>% 
  mutate(span =  max_age - min_age) %>% 
  filter(span != 0) %>% 
  select(-span)

head(refs_occurance_format2)
```

We can make a histogram showing the distribution of the number of years each cited article was cited for (article lifespan):

```{r}
refs_occurance_format_hist <- 
  refs_occurance_format2 %>% 
  mutate(number_of_years_cited = max_age - min_age + 1)

# ggplot(refs_occurance_format_hist,
#          aes(number_of_years_cited)) +
#   geom_histogram()

hist(refs_occurance_format_hist$number_of_years_cited,
     main = paste("Number of years each cited article was cited for"),
     xlab = "Number of years cited")
```

And what about the paper published in each 5-year interval of our data that has been cited over the longest duration? In fact there are many ties here, so we've just randomly sampled from each 5 year interval. 

```{r}
# set up lookup table for 5-year intervals
year1 <- 1975:2020
my_seq <- seq(year1[1], year1[length(year1)], by = 5)
indx <- findInterval(year1, my_seq)
ind <- seq(1, length(my_seq), by = 1)
labl1 <- paste(my_seq[ind], my_seq[ind + 1], sep = "-")[-42]
dat5 <- data_frame(year = year1, 
                   five_year = labl1[indx])


refs_occurance_format_hist_year <- 
refs_occurance_format_hist %>% 
  mutate(year = as.numeric(str_extract(Species, "[0-9]{4}"))) %>% 
  mutate(year = if_else(year %in% 1975:2017, year, 0)) %>% 
  filter(year >= 1975) %>% 
   left_join(dat5, by = 'year') %>% 
  group_by(five_year) %>% 
  filter(number_of_years_cited == max(number_of_years_cited)) %>% 
  distinct(Species, 
           number_of_years_cited, 
           year) %>% 
  slice(1)

refs_occurance_format_hist_year %>% 
  mutate(titles  = str_wrap(str_trunc(Species, 40), 10)) %>% 
  mutate(end_year = year + number_of_years_cited) %>% 
  mutate(end_year = if_else(end_year > 2017, 2017, end_year)) %>% 
  ungroup() %>% 
  select(titles, year, end_year) %>% 
  ggplot() +
  geom_linerange(aes(x = reorder(titles, year),
                     ymin = year,
                     ymax = end_year),
                 size = 2) +
  geom_point(aes(x = reorder(titles, year),
                 year),
             size = 4) +
    geom_point(aes(x = reorder(titles, year),
                 end_year),
               size = 4) +
  ylim(c(1975, 
         2017)) +
  coord_flip()
 

```

## Bayesian estimation of diversification

From https://www.nature.com/articles/palcomms201619:

The diversification of citations through time is modelled here as the product of both origination and extinction. The estimation of origination and extinction rates utilizes an underlying birth–death model, which assumes these processes are random events occurring through continuous time. The probability of events occurring at any given time is determined by parameters of the birth–death process, which express the expected number of origination (or extinction) events per lineage per units of time. Rates can vary through time by introducing rate shifts (Silvestro et al., 2014b; Stadler, 2011; Stadler, 2012).

The first year that an article is cited is considered as an origination event, with the last year it was cited is characterized as an extinction event. To speed up the computations we will convert the _occurance_ format to a _lineage_ format, where each cited item only appears once in the table with its earliest and latest years of citation. 

The next step is to prepare this occurance data frame for input into Python to compute estimations of the origination, extinction and preservation rates. This is accomplished by calling the `extract.ages` function which extracts the ages and creates a readable python file: 

```{r, eval=TRUE}
library(pyrater)

# can't do it with occurance format: Error: cannot allocate vector of size 29.5 Mb 
# so let's use the lineage format, where each citation only appears once
refs_lineage_format <- 
  refs_occurance_format2 %>% 
  group_by(Species) %>% 
  summarise(first_year = min(min_age),
            last_year = max(max_age)) %>% 
  mutate(taxa = "NA") %>% 
  select(taxa, 
         Species,
         first_year,
         last_year)

# must be  c("clade", "species", "min_age", "max_age")

refs_species_pyrate_data <- lineage_pyrate(refs_lineage_format)

refs_species_pyrate_data$species_pyrate_data$clade <- 0

#  We can preview each data frame:
lapply(refs_species_pyrate_data, head)

```

We write a text file to be used with the PyRate analysis later on. This file will appear in our current working directory 

```{r, eval=TRUE}
write.table(refs_species_pyrate_data$species_pyrate_data,
            "lineage_pyrate_data.txt",
            quote=FALSE,
            sep="\t",
            row.names = FALSE)
```

A python file titled `lineage_pyrate_data_PyRate.py` should have been created and available in the working directory.

# Summary Plots

Prior to starting the PyRate analysis, it is good practice to get a sense of the data by developing a series of plots.  Using the function below, the following plots are created

1. Log Lineages Through Time
2. Cumulative Diversity Through Time
3. Average Lifespan Through Time
4. Histogram of Lifespans

### Citation Data (Lineage Data)

```{r, eval=TRUE, fig.height=10, fig.width=14}
# The numeral indicates the x-axis increments with 
# the number 5 indicating 5-year time bins
# windows() # if interactive
summary_plots(refs_species_pyrate_data$species_pyrate_data, 5) 
```

### Choosing the best underlying model

From https://www.nature.com/articles/palcomms201619 :

The first decision to be made in the analysis of cultural data is whether a birth-death model is an appropriate model for the data under analysis. In this analysis, a birth-death model refers to a continuous-time Markov process where in each time step a the unit of analysis (typically a lineage or new product) can either originate (birth) or go extinct (death). Being that the birth-death model is an example of a continuous-time Markov process, the emergence or discontinuation of a lineage in the future depends on the current state of the model in the previous time step. In PyRate, if a birth-death model is favored, this means that the origination or extinction of a cultural lineage or material culture product is influenced by the existing number of lineages in the previous time step. This can be seen as suggestive of incremental innovation where the emergence of a new lineage or product is strongly influenced by the previous lineage or products available, likely through minor modifications of existing traits. A birth-death model is generally suggestive of a strong inheritance pattern between generations of cultural lineages or artifacts. (For example, a new car model that is a combination of traits from other already existing car models).   

In contrast to many biological systems, where birth-death models have been shown to be very reliable, it is not always known if a birth-death model is appropriate for cultural data.  An alternative model, developed for this research, is an immigration-death model. In this model, the emergence or discontinuation of a lineage or product is independent of the previous states of the model. This models has an underlying Poisson distribution which highlights that the emergence or discontinuation of a cultural lineage or product would occur randomly in each time step.  This can be seen as suggestive of more radical innovation or horizontal transmission of traits from individuals or technologies from outside of the direct lineages. (For example, a new car model that has novel traits that were developed in the airline industry). 

In order to test between these two models, the data set will be analyzed in two separate analysis using the mBDI function In order to execute the analysis, the following commands will execute Python code. You need to have Python 2.7 installed for this to work. You can download this from <https://www.python.org/>. You will also need numpy and scipy for your Python installation. The `mBDI` function will try to guess where Python is on you computer, but if it guesses wrong and return an error, you may need to set the `path_to_python` argument to the `mBDI` function to ensure that it can find where Python is installed on your computer. See `?mBDI` for more details. 

Upon executing these commands, a new folder will be created in your working directory  called `pyrate_mcmc_logs`.

```{r, eval=FALSE}

# set the number of generations. 10,000,000 generations = 10 hrs

n_generations <- 10000

library(pyrater)

# birth-death model
mBDI(path = "C:/python27/python.exe",
     n_generations = n_generations, 
     model = 0, 
     data_format = "lineage",
     input_file = "lineage_pyrate_data.txt")
# elapsed time: 3544.91 sec

# immigration-death model
mBDI(path = "C:/python27/python.exe",
     n_generations = n_generations, 
     model = 1, 
     data_format = "lineage", 
     input_file = "lineage_pyrate_data.txt") 
#elapsed time: 1867.96 " 
```


This analysis uses the default settings of samples every 1,000 generations for 10,000,000 generations.  Details about changes to PyRate default settings can be found in Silvestro et al. 2014. If access to a computing cluster is available, this is the preferred option. To reduce the run time of the analysis, simply adjust the number of generations from 10 million to 1 million.  

# Visualizing the Rates of Origination and Extinction

Once the BDMCMC runs are finished, one can easy view the a rate through time plot by using the following commands:

```{r, eval=FALSE}

pyrate_plot(path_to_python = "C:/python27/python.exe",
            input_file = "pyrate_mcmc_logs/lineage_pyrate_data_0_BD_marginal_rates.log")


```

These plots will use the default plot setting in PyRate and create both an R file and pdf with the rate-through-time plots. Open the pdf and check out the rates of origination and extinction through time!

We can redraw these plots in R:

```{r, eval=TRUE}
source(paste0(here::here(), "/pyrate_mcmc_logs/lineage_pyrate_data_0_BD_marginal_rates_RTT.r"))

age_rev <-
  2017 + age # adjust for the most recent date in each of the datasets

# Origination
plot(
  age_rev,
  L_hpd_M95,
  type = 'n',
  ylim = c(0, max(L_hpd_M95)),
  xlim = c(min(age_rev), max(age_rev)),
  xlab = "Years",
  ylab = "Rate of Event Per Lineage Per Time Unit",
  main = "Origination"
)
plot_RTT(age_rev, L_hpd_M95, L_hpd_m95, L_mean, "navyblue")

# Extinction
plot(
  age_rev,
  M_hpd_M95,
  type = 'n',
  ylim = c(0, max(M_hpd_M95)),
  xlim = c(min(age_rev), max(age_rev)),
  xlab = "Years",
  ylab = "Rate of Event Per Lineage Per Time Unit",
  main = "Extinction"
)
plot_RTT(age_rev, M_hpd_M95, M_hpd_m95, M_mean, "red")

# Net Diversification
plot(
  age_rev,
  R_hpd_M95,
  type = 'n',
  ylim = c(min(R_hpd_m95), max(R_hpd_M95)),
  xlim = c(min(age_rev), max(age_rev)),
  xlab = "Years",
  ylab = "Rate of Event Per Mineage Per Time Unit",
  main = "Net Diversification"
)
plot_RTT(age_rev, R_hpd_M95, R_hpd_m95, R_mean, "darkgreen")
```

# Model testing between the BD/ID models

It is important to note that we are unable to quantitatively test whether a birth-death or immigration-death model best fits our data from the plotting of origination, extinction and net diversification rates.  In order to identify the best-fitting model we need to model test between all the most likely models. 

To determine the best fitting model, we want to first know how many different rates fit our data.  It is unlikely that the rates of origination and extinction for cultural data through time are constant, but we don't know how many rates best fit the data that we have.  In order to determine this, run the following commands

```{r, eval=FALSE}

one_BD <- mProb(path_to_python = "C:/python27/python.exe",
                input_file = "pyrate_mcmc_logs/lineage_pyrate_data_0_BD_mcmc.log")


mProb(path_to_python = "C:/python27/python.exe",
      input_file = "pyrate_mcmc_logs/lineage_pyrate_data_0_ID_mcmc.log")
```

The input file paths are: 

pyrate_mcmc_logs/occurrence_pyrate_data_1BD_mcmc.log
pyrate_mcmc_logs/occurrence_pyrate_data_1ID_mcmc.log
pyrate_mcmc_logs/lineage_pyrate_data_1BD_mcmc.log
pyrate_mcmc_logs/lineage_pyrate_data_1ID_mcmc.log


PyRate will provide a breakdown of the probability of most likely rate models for both speciation and extinction. In addition the best configuration of rates of also provided. It is probably best to open a spreadsheet (excel or Google sheets) and record these values. 

# Methods

# Results

# Discussion

# Conclusion

# Acknowledgements

# References 

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies: 

```{r colophon, cache = FALSE}
# which R packages and versions?
devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? You may need to change the path value
# if your Rmd is not in analysis/paper/
git2r::repository("../..")
```
